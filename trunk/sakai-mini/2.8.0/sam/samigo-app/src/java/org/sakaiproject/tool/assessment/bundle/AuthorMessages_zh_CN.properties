#writed by MergeProp
#Thu Jul 21 22:09:45 CST 2011
MCanswer_outofbound_error=\u591a\u9879\u9009\u62e9\u6700\u591a\u5141\u8bb826\u4e2a\u9009\u9879\u3002
a_back=x
a_cancel=x
a_create=a
a_import=i
a_level_feedb=\u5bf9\u56de\u7b54\u7684\u53cd\u9988
a_options=s
a_remove=r
a_save=s
a_title=t
above_average=\u9ad8\u4e8e\u5e73\u5747\u6c34\u5e73
action_duplicate=\u590d\u5236
action_edit=\u7f16\u8f91
action_export=\u5bfc\u51fa
action_preview=\u9884\u89c8
action_print=\u6253\u5370
action_publish=\u53d1\u5e03
action_remove=\u5220\u9664
action_scores=\u8bc4\u5206
action_settings=\u8bbe\u7f6e
add_attachments=\u6dfb\u52a0\u9644\u4ef6
add_items=\u6dfb\u52a0\u9879\u76ee\uff1a
add_matches=\u6dfb\u52a0\u5339\u914d\uff1a
add_more_answer_sect=\u6dfb\u52a0\u989d\u5916\u7684\u56de\u7b54\u90e8\u5206\uff1a--
add_more_answer_sects=\u6dfb\u52a0\u989d\u5916\u7684\u56de\u7b54\u90e8\u5206\uff1a--
add_q=\u6dfb\u52a0\u95ee\u9898\uff1a
add_remove_attachments=\u6dfb\u52a0/\u5220\u9664\u9644\u4ef6
addr=\u5730\u5740\uff1a
admin=\u7ba1\u7406\u5458
agree=\u540c\u610f
all_user_input_saved=\u81ea\u52a8\u4fdd\u5b58\u7528\u6237\u8f93\u5165\u3002
allow_only_specified=\u4ec5\u5141\u8bb8\u6307\u5b9aIP
an_assessment_must_co=\u4e00\u4e2a\u6d4b\u9a8c\u81f3\u5c11\u5e94\u8be5\u5305\u542b\u4e00\u4e2a\u95ee\u9898\u624d\u53ef\u4ee5\u53d1\u5e03
anonymous=\u533f\u540d
anonymous_grading_on=\u53ea\u5141\u8bb8\u533f\u540d\u8bc4\u5206
another_p=\u53e6\u4e00\u90e8\u5206
answer=\u9009\u9879\u7b54\u6848
answerKey=\u53c2\u8003\u7b54\u6848
answerList_error=\u81f3\u5c11\u8f93\u51652\u4e2a\u53ef\u4f9b\u9009\u62e9\u7684\u7b54\u6848\u3002
answer_point_value=\u5206\u503c
answer_provide_a_mo=\u7b54\u6848\uff1a\u63d0\u4f9b\u6807\u51c6\u7b54\u6848\u7ed9\u5b66\u751f\uff0c\u5e2e\u52a9\u8bc4\u5206\u8005\u5904\u7406\u53cd\u9988\u3002
answer_text_predefi=\u9898\u5e72\uff1a\u9884\u5b9a\u4e49\u8c03\u67e5\u62a5\u544a\u7684\u8c03\u67e5\u8303\u56f4\u3002
answers=\u56de\u7b54
answers_select_answ=\u56de\u7b54\uff1a\u4ece\u4e0b\u9762\u9009\u62e9\u7b54\u6848\u3002
append_copy_title=- \u526f\u672c \#
as_listed_on_assessm=\u6309\u7167\u6d4b\u9a8c\u9875\u9762\u987a\u5e8f
assessment=\u6d4b\u9a8c
assessment_introduct=\u6d4b\u9a8c\u4ecb\u7ecd
assessment_metadata=\u6d4b\u9a8c\u5143\u6570\u636e
assessment_organizat=\u6d4b\u9a8c\u7ec4\u7ec7
assessment_released=\u6d4b\u9a8c\u5bf9\u8c61
assessment_title=\u6d4b\u9a8c\u6807\u9898
assessment_title_colon=\u6d4b\u9a8c\u6807\u9898
assign_to=\u5206\u914d\u7ed9
assign_to_p=\u6307\u5b9a\u90e8\u5206
assign_to_q_p=\u6307\u5b9a\u9898\u5e93
assign_to_question_p=\u6307\u5b9a\u9898\u5e93
attachments=\u9644\u4ef6
audio_recording=\u5f55\u97f3\u9898
authenticated_users=\u6240\u6709\u7528\u6237
author_s=\u4f5c\u8005
auto_save=\u81ea\u52a8\u4fdd\u5b58
auto_submit_when_tim=\u8d85\u65f6\u81ea\u52a8\u63d0\u4ea4
available=\u53ef\u7528
average=\u5e73\u5747\u6c34\u5e73
below_average=\u4f4e\u4e8e\u5e73\u5747\u6c34\u5e73
bg_color=\u80cc\u666f\u8272
bg_image=\u80cc\u666f\u56fe\u7247
browse=\u6d4f\u89c8
but_remember=\u4f46\u662f\u8bb0\u4f4f
button_add=\u6dfb\u52a0
button_back=\u56de\u9000
button_cancel=\u53d6\u6d88
button_close=\u5173\u95ed
button_copy=\u590d\u5236
button_edit=\u7f16\u8f91
button_modify=\u4fee\u6539
button_publish=\u53d1\u5e03
button_remove=\u5220\u9664
button_republish=\u91cd\u65b0\u53d1\u5e03
button_republish_and_regrade=\u91cd\u65b0\u8bc4\u5206\u5e76\u53d1\u5e03
button_return=\u8fd4\u56de
button_save=\u4fdd\u5b58
button_save_pair=\u4fdd\u5b58\u914d\u5bf9
button_save_pub=\u4fdd\u5b58\u5e76\u53d1\u5e03\u6d4b\u9a8c
button_save_settings=\u4fdd\u5b58
button_update_points=\u66f4\u65b0\u5206\u503c
case_sensitive=\u533a\u5206\u5927\u5c0f\u5199
cert_rem_assmt=\u786e\u8ba4\u5220\u9664\u8be5\u6d4b\u9a8c\u2014\u2014
cert_rem_attachment=\u786e\u5b9a\u8981\u79fb\u9664\u9644\u4ef6\u4e48\uff1f
cert_rem_q=\u786e\u8ba4\u8981\u5220\u9664\u8be5\u95ee\u9898\uff1f
change=\u66f4\u6539
change_q_type=\u66f4\u6539\u95ee\u9898\u7c7b\u578b
change_question_type=\u66f4\u6539\u95ee\u9898\u7c7b\u578b
choice_labels=A\:B\:C\:D\:E\:F\:G\:H\:I\:J\:K\:L\:M\:N\:O\:P\:Q\:R\:S\:T\:U\:V\:W\:X\:Y\:Z
choose_rem=\u8bf7\u9009\u62e9\u4f60\u8981\u5220\u9664\u7684
choose_which_of_the=\u8bf7\u4ece\u4e0b\u9762\u9009\u62e9\u6700\u5339\u914d\u5173\u7cfbChina is to Asia\u7684\u9009\u9879\uff1a_ is to _\u3002
collect_metadata_for_p=\u4f7f\u7528\u95ee\u9898\u7f16\u8f91\u5668\u4e3a\u201c\u90e8\u5206\u201d\u6536\u96c6\u5143\u6570\u636e
collect_metadata_for_q=\u4f7f\u7528\u95ee\u9898\u7f16\u8f91\u5668\u4e3a\u201c\u95ee\u9898\u201d\u6536\u96c6\u5143\u6570\u636e
column=\: 
continuous_numbering=\u5728\u201c\u90e8\u5206\u201d\u4e4b\u95f4\u8fde\u7eed\u7f16\u53f7
copy_action=\u590d\u5236
copy_all_to_pool=\u5c06\u6240\u6709\u9898\u76ee\u62f7\u8d1d\u5230\u9898\u5e93
copy_assessment_conf_info_1=\u786e\u5b9a\u590d\u5236\u540d\u4e3a\u201c
copy_assessment_conf_info_2=\u201d\uff1f
copy_assessment_heading_conf=\u6d4b\u9a8c\u590d\u5236\u786e\u8ba4
copy_to_pool=\u62f7\u8d1d\u5230\u9898\u5e93
corrAnswer=\u4f60\u81f3\u5c11\u8981\u9009\u62e9\u4e00\u4e2a\u9009\u9879\u3002
correct=\u6b63\u786e
correctItemFeedback=\u6b63\u786e\u53cd\u9988
correct_answer=\u6b63\u786e\u7b54\u6848
correct_answer_opti=\u6b63\u786e\u7b54\u6848\uff08\u53ef\u9009\uff09
correct_incorrect_an=\u6b63\u786e/\u9519\u8bef\u56de\u7b54\u53cd\u9988
correct_match_feedback_opt=\u6b63\u786e\u5339\u914d\u53cd\u9988\uff08\u53ef\u9009\uff09
correct_response=\u6b63\u786e\u56de\u7b54
create_modify_a=\u6dfb\u52a0/\u4fee\u6539\u6d4b\u9a8c
create_modify_p=\u6dfb\u52a0/\u4fee\u6539\u201c\u90e8\u5206\u201d
create_pairing=\u6dfb\u52a0/\u7f16\u8f91\u914d\u5bf9\u548c\u53cd\u9988\uff08\u53ef\u9009\uff09
creator=\u521b\u5efa\u8005
dash=-
default=\u9ed8\u8ba4
deliveryDate_error=\u53d1\u5e03\u65e5\u671f\u683c\u5f0f\u4e0d\u6b63\u786e\uff1amm/dd/yyyy hh\:mm\:ss\:aa.
delivery_dates=\u53d1\u5e03\u65e5\u671f
denied_create_assessment_error=\u62b1\u6b49\uff0c\u60a8\u5f53\u524d\u6743\u9650\u4e0d\u5141\u8bb8\u521b\u5efa\u65b0\u7684\u6d4b\u9a8c\u6216\u8005\u5bfc\u5165\u6d4b\u9a8c\u3002
denied_delete_assessment_error=\u62b1\u6b49\uff0c\u60a8\u6ca1\u6709\u6743\u9650\u5220\u9664\u672c\u7ad9\u70b9\u7684\u6d4b\u9a8c\u3002
denied_delete_other_members_assessment_error=\u62b1\u6b49\uff0c\u60a8\u6ca1\u6709\u6743\u9650\u5220\u9664\u7531\u5176\u4ed6\u7ad9\u70b9\u6210\u5458\u521b\u5efa\u7684\u6d4b\u9a8c\u3002
denied_edit_assessment_error=\u62b1\u6b49\uff0c\u60a8\u6ca1\u6709\u6743\u9650\u4fee\u6539\u672c\u7ad9\u70b9\u7684\u6d4b\u9a8c\u3002
denied_edit_publish_assessment_settings_error=\u62b1\u6b49\uff0c\u56e0\u60a8\u6ca1\u6709\u6743\u9650\u5728\u672c\u7ad9\u70b9\u53d1\u5e03\u6d4b\u9a8c\uff0c\u56e0\u800c\u4e5f\u4e0d\u80fd\u7f16\u8f91\u6d4b\u9a8c\u8bbe\u7f6e\u3002
denied_grade_assessment_error=\u62b1\u6b49\uff0c\u60a8\u6ca1\u6709\u5728\u672c\u7ad9\u70b9\u4e2d\u4e3a\u6d4b\u9a8c\u8bc4\u5206\u7684\u6743\u9650\u3002
denied_publish_assessment_error=\u62b1\u6b49\uff0c\u60a8\u6ca1\u6709\u6743\u9650\u5728\u672c\u7ad9\u70b9\u53d1\u5e03\u6d4b\u9a8c\u3002
denied_submit_for_grade_error=\u62b1\u6b49\uff0c\u60a8\u6ca1\u6709\u6743\u9650\u5728\u672c\u7ad9\u70b9\u63d0\u4ea4\u6d4b\u9a8c\u5e76\u8bc4\u5206\u3002
denied_take_assessment_error=\u62b1\u6b49\uff0c\u60a8\u4e0d\u80fd\u53c2\u52a0\u672c\u7ad9\u70b9\u7684\u6d4b\u9a8c\uff0c\u4f46\u53ef\u4ee5\u6d4f\u89c8\u3002
description_asi_aut=\u63cf\u8ff0\uff1aASI Author XML Style Sheet
description_intro_o=\u63cf\u8ff0/\u4ecb\u7ecd\uff08\u53ef\u9009\uff09
disagree=\u4e0d\u540c\u610f
disagree_agree=\u4e0d\u540c\u610f\uff0c\u540c\u610f
disagree_undecided=\u4e0d\u540c\u610f\uff0c\u4e0d\u786e\u5b9a\uff0c\u540c\u610f
due=\u8fc7\u671f
duplicateName_error=\u6d4b\u9a8c\u6807\u9898\u4e0d\u80fd\u91cd\u540d\uff0c\u8bf7\u53e6\u884c\u53d6\u540d\u3002
each_p_is_on_a_se=\u4e00\u4e2a\u90e8\u5206\u4e00\u4e2a\u9875\u9762
each_q_is_on=\u4e00\u4e2a\u95ee\u9898\u4e00\u4e2a\u9875\u9762
edit_part=\u7f16\u8f91
edit_published_assessment_error=\u6d4b\u9a8c\u4e0d\u53ef\u518d\u7f16\u8f91
edit_published_assessment_error_info=\u81f3\u5c11\u6709\u4e00\u540d\u5b66\u751f\u5df2\u7ecf\u5f00\u59cb\u505a\u672c\u6d4b\u9a8c\uff0c\u6d4b\u9a8c\u4e0d\u53ef\u518d\u7f16\u8f91\u3002\u70b9\u51fb\u201c\u8fd4\u56de\u201d\u8fd4\u56de\u6d4b\u9a8c\u9875\u9762\u3002
edit_published_assessment_heading_conf=\u7f16\u8f91\u5df2\u53d1\u5e03\u6d4b\u9a8c\u7684\u786e\u8ba4
edit_published_assessment_heading_conf_info_1=\u672c\u6d4b\u9a8c\u5df2\u53d1\u5e03\u3002
edit_published_assessment_heading_conf_info_2=\u5b83\u5c06\u88ab\u64a4\u56de\uff08\u5bf9\u5b66\u751f\u4e0d\u53ef\u7528\uff09\uff0c\u76f4\u5230\u60a8\u91cd\u65b0\u53d1\u5e03\u5b83\u3002
edit_published_assessment_heading_conf_info_3=\u70b9\u51fb\u201c\u7f16\u8f91\u201d\u64a4\u56de\u672c\u6d4b\u9a8c\uff0c\u7136\u540e\u4fee\u6539\u3002
edit_published_assessment_heading_conf_info_4=\u70b9\u51fb\u201c\u53d6\u6d88\u201d\u8fd4\u56de\u6d4b\u9a8c\u9875\u9762\u3002
edit_published_assessment_warn_1=\u672c\u6d4b\u9a8c\u5df2\u88ab\u64a4\u56de\u3002
edit_published_assessment_warn_21=\u70b9\u51fb\u201c\u91cd\u65b0\u53d1\u5e03\u201d\u6216\u201c\u91cd\u65b0\u53d1\u5e03\u5e76\u8bc4\u5206\u201d\u4f7f\u5176\u5bf9\u5b66\u751f\u53ef\u89c1\u3002
edit_published_assessment_warn_22=\u70b9\u51fb\u201c\u91cd\u65b0\u53d1\u5e03\u201d\u4f7f\u5176\u5bf9\u5b66\u751f\u53ef\u89c1\u3002
editor=\u7f16\u8f91\u5668
emptyText_error=\u95ee\u9898\u6587\u672c\u4e0d\u80fd\u4e3a\u7a7a\u3002
empty_correct_error=\u6b63\u786e\u7b54\u6848\u7684\u6587\u672c\u6846\u4e0d\u80fd\u4e3a\u7a7a\u3002
empty_part_title_error=\u5927\u9898\u7684\u6807\u9898\u4e0d\u80fd\u4e3a\u7a7a\u3002
enable_nagative_marking=Enable Negative Marking
enable_negative_makrinkg_note=<b>NOTE\:</b> Even though a question may have a negative point value, the final point value for an assessment will not be less than zero.
enable_negative_makrinkg_text=Select this option if you want to discourage random guessing. The value entered into the "Negative point value..." field will be the question's point value if a student makes an incorrect selection. For instance, if a question is worth 10 points and you enter "5" into the "Negative point value..." field, a correct answer selection would be worth 10 points and an incorrect answer selection would be worth -5 points.  
enable_partial_credit=Enable Partial Credit
enable_partial_credit_text=Select this option if you want to give students partial credit when they choose an answer that is "almost correct." For instance, question X has options A, B, C, D, where A is the correct answer. If students pick A, they would receive full credit, but they could be given some credit for choosing an answer that is almost correct. Enabling this option will allow you to specify a percentage value for each answer.
enter_new_pc_value=\u8f93\u5165\u65b0\u7684\u503c\uff08\u53ef\u9009\uff09
excellent=\u4f18\u79c0
existing_q=\u5df2\u6709\u95ee\u9898
existing_qs=\u5df2\u6709\u95ee\u9898
false_msg=\u9519\u8bef
feedback=\u53cd\u9988
feedback_delivery=\u53cd\u9988\u9012\u9001
feedback_optional=\u53cd\u9988\uff08\u53ef\u9009\uff09
feedback_will_be_dis=\u5728\u6307\u5b9a\u65f6\u95f4\u53cd\u9988\u7ed9\u5b66\u751f
file=\u6587\u4ef6\uff1a
file_upload=\u4e0a\u4f20\u6587\u4ef6
file_upload_example=\u6587\u4ef6\u4e0a\u4f20\u793a\u4f8b
fill_in_numeric=\u6570\u503c\u9898
fill_in_the_blank=\u586b\u7a7a\u9898
for_example_curly=\u4f8b\u5982\uff1aRoses are {red} and violets are {blue}.
for_example_curly_fin=\u4f8b\u5982\uff1a   3*3\= {9} y 2+2\= {4}
for_example_pipe=\u4f8b\u5982\: The sides are {heads|tails}.
for_example_pipe_fin=\u4f8b\u5982\uff1a\u4ef7\u683c\u5728 {12.2|14.5}. (12.2 \u523014.5 \u7684\u4efb\u4f55\u503c\u90fd\u662f\u6709\u6548\u7b54\u6848)
generalItemFeedback=\u53cd\u9988
general_fb=\u4e00\u822c\u9879\u76ee\u53cd\u9988
global_nav_assessmt=\u6d4b\u9a8c
global_nav_pools=\u9898\u5e93
global_nav_template=\u6a21\u677f
gradebook_exception_error=\u8b66\u544a\uff1a\u672c\u6d4b\u9a8c\u4e0d\u80fd\u521b\u5efa\u6210\u7ee9\u518c\u6761\u76ee\uff0c\u8bf7\u5230\u672c\u5730help desk\u5bfb\u6c42\u5e2e\u52a9\u3002
gradebook_exception_min_points=\u8b66\u544a\uff1a\u65e0\u6cd5\u4e3a\u672c\u6d4b\u9a8c\u521b\u5efa\u6210\u7ee9\u518c\uff0c\u56e0\u4e3a\u6210\u7ee9\u518c\u8981\u6c42\u6d4b\u9a8c\u603b\u5206\u5fc5\u987b > 0\uff0c\u8bf7\u5728\u8bbe\u7f6e\u4e2d\u5c06\u6210\u7ee9\u518c\u9009\u9879\u6539\u4e3a\u201c\u65e0\u201d\uff0c\u7136\u540e\u91cd\u65b0\u53d1\u5e03\u3002
gradebook_options=\u6210\u7ee9\u518c\u9009\u9879
gradebook_service_error=\u8b66\u544a\:\u6210\u7ee9\u518c\u6ca1\u6709\u6b63\u786e\u914d\u7f6e\u3002\u56e0\u6b64\uff0c\u65b0\u6d4b\u9a8c\u4e0d\u80fd\u521b\u5efa\u3002\u8bf7\u8054\u7cfb\u672c\u5730\u670d\u52a1\u53f0\u6c42\u52a9\u3002
grader_s_comme=\u8bc4\u5206\u8005\u6ce8\u89e3
grading=\u8bc4\u5206
grading_options=\u8bc4\u5206\u9009\u9879
graphics=\u56fe\u7247
greater=>
high_security=\u5b89\u5168\u5b9a\u4e49
hrs=\u5c0f\u65f6
if_multiple_submissi=\u5982\u679c\u6bcf\u4eba\u591a\u6b21\u63d0\u4ea4
image=\u56fe\u7247
img_delete=/images/icons/delete.png
img_edit=/images/icons/pencil.png
img_part_delete=/images/icons/page_delete.png
img_part_edit=/images/icons/page_edit.png
immediate_feedback=\u5373\u65f6\u53cd\u9988
import_an_assessment=\u5bfc\u5165\u4e00\u4e2a\u6d4b\u9a8c
import_from_a_file=\u4ece\u6587\u4ef6\u5bfc\u5165
import_from_q=\u4ece\u9898\u5e93\u62f7\u8d1d
import_from_question=\u4ece\u9898\u5e93\u5bfc\u5165
import_from_question_bank=*** Import from Question Bank
incorrect=\u9519\u8bef
incorrectItemFeedback=\u9519\u8bef\u53cd\u9988
incorrect_answer_op=\u9519\u8bef\u56de\u7b54\uff08\u53ef\u9009\uff09
incorrect_match_feedback_opt=\u9519\u8bef\u5339\u914d\u53cd\u9988\uff08\u53ef\u9009\uff09
information=\u4fe1\u606f
ins_new_q=\u63d2\u5165\u65b0\u7684\u95ee\u9898
insert_additional_a=\u63d2\u5165\u66f4\u591a\u9009\u9879
insert_p=\u63d2\u5165\u201c\u5927\u9898\u201d
insert_q=\u63d2\u5165\u95ee\u9898
item=\u9879\u76ee
item_display_author=\u9879\u76ee\u663e\u793a\uff0d\u7f16\u8f91\u6a21\u5f0f
items=\u9879\u76ee
key=\u5173\u952e\u5b57
keyword=\u5173\u952e\u5b57
late_handling=\u8fdf\u4ea4\u5904\u7406
late_submissions_af=\u62d2\u7edd\u8fdf\u4ea4\uff08\u8fc7\u671f\u65e5\u671f\uff09
late_submissions_wil=\u5141\u8bb8\u8fdf\u4ea4\uff0c\u4f46\u4f1a\u5f71\u54cd\u8bc4\u5206\u3002
linear_access_to_que=\u987a\u5e8f\u7b54\u9898\uff0c\u4e0d\u53ef\u8fd4\u56de\u4e0a\u4e00\u9875\u9762<br/> &nbsp; &nbsp; &nbsp; \u53ea\u6709\u201c\u4e0b\u4e00\u9875\u201d\u6309\u94ae\u7528\u4e8e\u524d\u8fdb<br/> &nbsp; &nbsp; &nbsp; \u6ca1\u6709\u76ee\u5f55\u9875<br/>match\=\u5339\u914d
match_error=\u4f60\u5fc5\u987b\u8f93\u5165\u9009\u9879\u548c\u5bf9\u5e94\u7684\u503c\u3002
matching=\u914d\u5bf9\u9898
matching_choice_col=\u9009\u9879
matching_currently_editing=\u6b63\u5728\u7f16\u8f91
matching_match_col=\u5339\u914d
matching_q_cont=\u5339\u914d\u95ee\u9898\uff0d\u7eed
mc_error=\u8bf7\u586b\u5199\u66f4\u591a\u7b54\u6848\u3002
mc_whats_this_main_text=\u9009\u62e9\u9898\u5c06\u6839\u636e\u60a8\u9009\u62e9\u7684\u5f97\u5206\u89c4\u5219\u8ba1\u7b97\u5206\u6570\u3002
mcms_whats_this_note=\ 
mcms_whats_this_text=\u591a\u9009\u9898\uff0c\u5168\u90e8\u9009\u62e9\u6b63\u786e\u5f97\u5168\u90e8\u5206\u6570\uff0c\u53ea\u8981\u6709\u4e00\u4e2a\u9009\u9879\u9519\u8bef\u5c06\u5f970\u5206\u3002
mcsc_whats_this_text=\u5355\u9009\u9898\uff0c\u9009\u62e9\u6b63\u786e\u5f97\u5168\u90e8\u5206\u6570\uff0c\u9009\u62e9\u9519\u8bef\u5f970\u5206\u3002\u8fd9\u4e2a\u9009\u9879\u53ef\u80fd\u4f1a\u88ab\u542f\u7528\u90e8\u5206\u7ed9\u5206\u6216\u8005\u542f\u7528\u6263\u5206\u8986\u76d6\u3002
mcsc_whats_this_text_no_partial_credit=\u5355\u9009\u9898\uff0c\u9009\u62e9\u6b63\u786e\u5f97\u5168\u90e8\u5206\u6570\uff0c\u9009\u62e9\u9519\u8bef\u5f970\u5206\u3002\u5982\u679c\u8981\u60e9\u7f5a\u5b66\u751f\u7684\u9519\u8bef\uff0c\u53ef\u4ee5\u5728\u201c\u56de\u7b54\u9519\u8bef\u6263\u9664\u7684\u5206\u503c\u201d\u8f93\u5165\u4e00\u4e2a\u5206\u6570\uff0c\u4f8b\u5982\u4e00\u4e2a\u9898\u76ee\u662f10\u5206\uff0c\u5728\u201c\u56de\u7b54\u9519\u8bef\u6263\u9664\u7684\u5206\u503c\u201d\u4e2d\u8f93\u5165\u4e865\uff0c\u5b66\u751f\u505a\u5bf9\u4e86\u5c06\u5f9710\u5206\uff0c\u5982\u679c\u9519\u4e86\u5c06\u5f97-5\u5206\u3002
mcss_whats_this_text=\u5355\u9009\u9898\uff0c\u6709\u591a\u4e2a\u6b63\u786e\u7b54\u6848\uff0c\u53ea\u8981\u9009\u62e9\u7684\u662f\u6b63\u786e\u7b54\u6848\uff0c\u5c06\u5f97\u5230\u5168\u90e8\u5206\u6570\uff0c\u5426\u5219\u5f970\u5206.\u4f8b\u5982\u7b54\u6848\u662fA\u3001B\u6216D\uff0c\u5982\u679c\u5b66\u751f\u9009\u62e9\u4e86A\u6216\u8005B\u6216\u8005D\u90fd\u5c06\u5f97\u5230\u5168\u90e8\u5206\u6570\uff0c\u5982\u679c\u9009\u62e9C\u5c06\u5f970\u5206\u3002
metadata=\u5143\u6570\u636e
mins=\u5206\u949f
missingChoices_error=\u8bf7\u8f93\u5165\u6b64\u9009\u9879\u6587\u672c
model_short_answer=\u7b80\u77ed\u53c2\u8003\u7b54\u6848\uff08\u53ef\u9009\uff09
modify_q=\u4fee\u6539\u95ee\u9898
multiCorrect_error=\u4f60\u81f3\u5c11\u5fc5\u987b\u9009\u62e9\u4e00\u4e2a\u6b63\u786e\u7b54\u6848\uff0c\u6b63\u786e\u7b54\u6848\u57df\u4e0d\u80fd\u4e3a\u7a7a\u3002
multipl_mc=\u591a\u4e2a\u6b63\u786e\u7b54\u6848
multipl_mc_ms=\u591a\u9879\u9009\u62e9\u9898
multipl_mc_ss=\u6709\u591a\u4e2a\u6b63\u786e\u7b54\u6848\uff0c\u4f46\u53ea\u5141\u8bb8\u9009\u62e9\u4e00\u4e2a
multiple_choice_mul=\u591a\u9879\u9009\u62e9\uff08\u591a\u4e2a\u7b54\u6848\uff09
multiple_choice_sin=\u5355\u9879\u9009\u62e9
multiple_choice_surv=\u8c03\u67e5\u95ee\u5377
multiple_choice_type=\u9009\u62e9\u9898
multiple_correct_ms=\u591a\u9879\u9009\u62e9\u9898
multiple_correct_ss=\u6709\u591a\u4e2a\u6b63\u786e\u7b54\u6848\uff0c\u4f46\u53ea\u5141\u8bb8\u9009\u62e9\u4e00\u4e2a
multiple_mc_ss_pc=\u542f\u7528\u90e8\u5206\u7ed9\u5206\u7684\u591a\u4e2a\u6b63\u786e\u7b54\u6848\uff0c\u5355\u9879\u9009\u62e9
mutually_exclusive=\u4e92\u65a5
mutually_exclusive_example=\u4f8b\u5982\: The sides of a coin are {heads|tails} and {heads|tails}. \u6b63\u786e\u7b54\u6848\: heads, tails\u3002 \u534a\u6b63\u786e\u7b54\u6848\: heads, heads\u3002
mutually_exclusive_note=\u6ce8\u610f\: \u5f53\u9009\u62e9\u6b64\u9009\u9879\u65f6\u65f6\uff0c\u5305\u542b\u591a\u4e2a\u7a7a\u800c\u6bcf\u4e2a\u7a7a\u7684\u7b54\u6848\u9009\u9879\u76f8\u540c\u7684\u95ee\u9898\u5fc5\u987b\u6709\u552f\u4e00\u7684\u7b54\u6848\u3002
my_assmts=\u6d4b\u9a8c
my_qp=\u9898\u5e93
my_qs=\u9898\u76ee
my_ts=\u6a21\u677f
navigation=\u5bfc\u822a
negative_point_value=\u56de\u7b54\u9519\u8bef\u6263\u9664\u7684\u5206\u503c
new_p=\u65b0\u5927\u9898
next_prev=\u9875\u9762\u4e0a\u7528\u4e8e\u6d4f\u89c8\u7684\u201c\u4e0b\u4e00\u9875\u201d\u548c\u201c\u4e0a\u4e00\u9875\u201d\u6309\u94ae
no=\u5426
noMatchingPair_error=\u5728\u4fdd\u5b58\u6b64\u95ee\u9898\u524d\uff0c\u4f60\u81f3\u5c11\u5fc5\u987b\u6709\u4e00\u4e2a\u914d\u5bf9\u3002\u8bf7\u8f93\u5165\u4e00\u4e2a\u914d\u5bf9\u7136\u540e\u70b9\u51fb\u201c\u4fdd\u5b58\u914d\u5bf9\u201d \u3002\u8fd9\u6837\u4f60\u53ef\u4ee5\u901a\u8fc7\u70b9\u51fb\u9875\u9762\u4e0b\u65b9\u7684\u201c\u4fdd\u5b58\u201d\u6309\u94ae\u6765\u4fdd\u5b58\u95ee\u9898\u3002
no_attachments=\u65e0\u9644\u4ef6
no_feedback_will_be=\u4e0d\u5bf9\u5b66\u751f\u663e\u793a\u4efb\u4f55\u53cd\u9988
no_matching_pair=\u76ee\u524d\u6ca1\u6709\u914d\u5bf9
no_toc=\u6ca1\u6709\u76ee\u5f55\u9875\u3002
none=\u65e0
not_correct=\u9519\u8bef
note_insert_pipe=\u5982\u679c\u6709\u591a\u79cd\u6b63\u786e\u7b54\u6848\uff0c\u53ef\u5c06\u6b63\u786e\u7b54\u6848\u5168\u90e8\u7f57\u5217\u4e8e{ }\u4e4b\u4e2d\uff0c\u4e2d\u95f4\u7528\u201c|\u201d\u5206\u9694\u3002
note_insert_pipe_fin=\u503c\u57df\uff1a\u5728\u503c\u57df\u95f4\u63d2\u5165\u7b26\u53f7\u201c|\u201d\u3002
note_negative_point_value_part=\u53ef\u9009\uff0c\u8986\u76d6\u8bd5\u9898\u7684\u76f8\u5e94\u503c\uff0c\u53ea\u9002\u7528\u4e8e\u5224\u65ad\u9898\u548c\u5355\u9009\u9898\u3002
note_negative_point_value_question=\u53ef\u9009\uff0c\u4ec5\u9002\u7528\u4e8e\u5224\u65ad\u9898\u548c\u5355\u9009\u9898\u3002
note_p_headers_w=\u6ce8\uff1a\u6807\u9898\u4e3a\u201c\u9ed8\u8ba4\u201d\u7684\u90e8\u5206\u5bf9\u53d7\u6d4b\u8005\u4e0d\u53ef\u89c1\u3002
note_place_curly=\u6ce8\uff1a\u5728\u9700\u8981\u8865\u7a7a\u7684\u8bcd\u5916\u9762\u9700\u8981\u653e\u7f6e\u82b1\u62ec\u53f7{}
note_place_curly_fin=\u6ce8\uff1a\u5728\u9700\u8981\u8865\u7a7a\u7684\u6570\u503c\u5916\u9762\u9700\u8981\u653e\u7f6e\u82b1\u62ec\u53f7{}
note_point_value_for_question=\u6ce8\u610f\uff1a\u53ef\u9009\u503c\uff0c\u8986\u76d6\u8bd5\u9898\u7684\u539f\u5206\u503c\u3002
number_of_attempts=\u5c1d\u8bd5\u6b21\u6570
number_of_attempts_indic=\u7ed9\u51fa\u5b66\u751f\u80fd\u91cd\u5f55\u51e0\u6b21\u56de\u7b54
number_of_qs=\u95ee\u9898\u6570
number_of_submission=\u5141\u8bb8\u63d0\u4ea4\u6b21\u6570
number_of_tries=\u5141\u8bb8\u5c1d\u8bd5\u6b21\u6570
number_questions=(\u9898\u76ee\u603b\u6570)
numbering=\u7f16\u53f7
obj=\u76ee\u6807
objective=\u76ee\u6807
one_per=\uff08\u4e00\u4e2a\u4e00\u884c\uff09
only=\u4ec5
only_next=\u53ea\u6709\u201c\u4e0b\u4e00\u9875\u201d\u6309\u94ae\u3002
org=\u7ec4\u7ec7
overdrawn_error=\u9898\u5e93\u9898\u76ee\u6570\u91cf\u4e0d\u8db3\uff0c\u8bf7\u8f93\u5165\u4e00\u4e2a\u8f83\u5c0f\u7684\u6570\u5b57\u3002
p=\u5927\u9898
p_information=\u5927\u9898\u4fe1\u606f
p_title=\u5927\u9898\u6807\u9898
part_dash=\u5927\u9898-
partial_credit_limit_detail=\u9700\u8981\u4e00\u4e2a0-99\u4e4b\u95f4\u7684\u6574\u6570\u3002
partial_credit_limit_summary="% Value" for an incorrect answer selection needs to be a whole number between 0 and 99.
password=\u5bc6\u7801
percentage_value=% Value
point_lower_case=\u5206
point_value_of_questons=\u6bcf\u4e00\u9898\u7684\u5206\u503c
points_lower_case=\u5206
pool_missingBracket_error=\u8bf7\u786e\u8ba4\u82b1\u62ec\u53f7\u7b26\u5408\u8981\u6c42\u5e76\u4e14\u7b54\u6848\u5fc5\u987b\u5305\u542b\u81f3\u5c11\u4e00\u4e2a\u975e\u7a7a\u683c\u5b57\u7b26\u3002
pool_name=\u5e93\u540d
preview=\u9884\u89c8
preview_model_short_answer=\u53c2\u8003\u56de\u7b54
pt=\u5f97\u5206
q=\u9898\u76ee
q_layout=\u9898\u76ee\u7248\u5f0f
q_level_feedb=\u5bf9\u9898\u76ee\u7684\u53cd\u9988
q_multiple=\u9898\u76ee\uff0d\u591a\u9879\u9009\u62e9\uff08\u591a\u4e2a\u7b54\u6848\uff09
q_ordering_n=\u9898\u76ee\u987a\u5e8f\uff08\u968f\u673a\u9009\u53d6\u65f6\u65e0\u6548\uff09
q_text=\u9898\u5e72
qdrawn_error=\u9898\u76ee\u6570\u5e94\u8be5\u662f\u4e00\u4e2a\u5927\u4e8e0\u7684\u6574\u6570\uff0c\u4f46\u4e0d\u5927\u4e8e
qdrawn_pt_error=\u95ee\u9898\u7684\u5206\u503c\u5e94\u5927\u4e8e\u6216\u7b49\u4e8e0
qs=\u9898\u76ee
question=\u9898\u76ee
question_lower_case=\u9898\u76ee
question_s_lower_case=\u9898\u76ee
question_text=\u9898\u5e72
questions_lower_case=\u9898\u76ee
random_access_to_que=\u4ece\u4e00\u4e2a\u76ee\u5f55\u968f\u610f\u9009\u62e9\u95ee\u9898\u56de\u7b54\u3002<br />\u63d0\u4f9b\u201c\u4fdd\u5b58\u5e76\u7ee7\u7eed\u201d\uff0c\u201c\u4e0b\u4e00\u9875\u201d\u6309\u94ae\u4f9b\u6d4f\u89c8\u3002
random_draw_from_que=\u4ece\u9898\u5e93\u4e2d\u968f\u673a\u9009\u53d6
random_draw_msg=\u672c\u5927\u9898\u7684\u9898\u76ee\u662f\u4ece\u9898\u5e93\u4e2d\u968f\u673a\u751f\u6210\u7684\u3002\u70b9\u51fb\u201c\u9884\u89c8\u6d4b\u9a8c\u201d\u53ef\u770b\u5230\u968f\u673a\u83b7\u53d6\u7684\u793a\u4f8b\u3002
random_draw_total_score=\u56e0\u8be5\u6d4b\u9a8c\u5305\u62ec\u4e00\u4e2a\u968f\u673a\u751f\u6210\u7684\u5927\u9898\uff0c\u6240\u4ee5\u603b\u5206\u53ea\u662f\u4e00\u4e2a\u4f30\u8ba1\u503c\u3002
random_draw_type=\u968f\u673a\u63d0\u53d6\u81ea
random_within_p=\u5927\u9898\u5185\u968f\u673a
randomize_answers=\u968f\u673a\u6392\u5217\u9009\u9879
randomize_items=\u968f\u673a\u6392\u5217\u9879\u76ee
randomized_per_student=\u5bf9\u6240\u6709\u7684\u6d4b\u9a8c\u5b66\u751f\u7684\u95ee\u9898\u53ea\u968f\u673a\u4e00\u6b21
randomized_per_submission=\u6bcf\u6b21\u6d4b\u9a8c\u65f6\u5019\u5b66\u751f\u7684\u9898\u76ee\u90fd\u662f\u968f\u673a\u7684\u3002
rationale=\u539f\u7406
record_the_average_s=\u8bb0\u5f55\u5e73\u5747\u6210\u7ee9
record_the_highest_s=\u8bb0\u5f55\u6700\u9ad8\u6210\u7ee9
regrade_republish=Republish vs. Regrade and Republish
rem_p_all=\u5220\u9664\u5927\u9898\u53ca\u9898\u76ee\u3002
rem_p_only=\u53ea\u5220\u9664\u5927\u9898\uff0c\u5c06\u9898\u76ee\u79fb\u81f3
remove_assessment_co=\u5220\u9664\u6d4b\u9a8c\u786e\u8ba4
remove_attachment=\u79fb\u9664
remove_attachment_conf=\u79fb\u9664\u9644\u4ef6\u786e\u8ba4
remove_attachment_heading=\u79fb\u9664\u9644\u4ef6
remove_p_conf=\u5220\u9664\u5927\u9898\u786e\u8ba4
remove_part=\u5220\u9664
remove_q_conf=\u5220\u9664\u95ee\u9898\u786e\u8ba4
remove_question_conf=\u5220\u9664\u95ee\u9898\u786e\u8ba4
req_rationale=\u8bf4\u660e\u539f\u7406
require_rationale=\u8bf4\u660e\u539f\u7406
reset_grading_logic=\u5145\u503c\u4e3a\u7f3a\u7701\u5f97\u5206\u89c4\u5219
reset_score_values=\u91cd\u7f6e\u5206\u503c
reset_to_default_grading_logic_text=Click this link if you change your mind after selecting 'Enable Partial Credit' or 'Enable Negative Marking'. The default grading logic grants full credit for selecting a correct answer and zero credit for selecting an incorrect answer.
restart_numbering_be=\u5927\u9898\u5185\u91cd\u65b0\u7f16\u53f7
retract=\u64a4\u9500
rube=\u91cf\u89c4
rubric_colon=\u91cf\u89c4
s_level_feedb=\u5bf9\u9009\u62e9\u7684\u53cd\u9988
sakai_assessment_man=\u6d4b\u9a8c\u7ba1\u7406
sakai_assessment_rem_q=\u6d4b\u9a8c\uff0d\u5220\u9664\u95ee\u9898
save_or_cancel_change=\u4fdd\u5b58\u6216\u53d6\u6d88\u66f4\u6539
scale10=1 -> 10
scale5=1 -> 5
secondary_id_and_pass=\u5907\u7528ID\u548c\u5bc6\u7801
select=[\u9009\u62e9]
select_a_pool_for_random_draw=\u9009\u62e9\u4e00\u4e2a\u5e93\u540d
select_a_pool_name=\u9009\u62e9\u5e93\u540d\uff08\u53ef\u9009\uff09
select_action=--\u9009\u62e9\u52a8\u4f5c--
select_combo=\u9009\u62e9
select_menu=\u9009\u62e9
select_num_questions=(
select_one=\u9009\u62e9\u4e00\u9879...
select_qtype=\u9009\u62e9\u95ee\u9898\u7c7b\u578b
select_the_feedback=\u9009\u62e9\u5c06\u663e\u793a\u7ed9\u5b66\u751f\u7684\u53cd\u9988\u7ec4\u4ef6
selected=\u5df2\u9009
selectedPool_error=\u8bf7\u9009\u62e9\u8981\u968f\u673a\u62bd\u9898\u7684\u9898\u5e93
selection_level_feed=\u5bf9\u9009\u62e9\u7684\u53cd\u9988
separator=| 
settings=\u8bbe\u7f6e\uff0d
short_answer_essay=\u7b80\u7b54\u9898\\\u8bba\u8ff0\u9898
show=\u663e\u793a
show_hide=\u663e\u793a/\u9690\u85cf
show_hide_editor=\u663e\u793a/\u9690\u85cf\u8d85\u6587\u672c\u7f16\u8f91\u5668
single=\u4e00\u4e2a\u6b63\u786e\u7b54\u6848
singleCorrect_error=\u4f60\u5fc5\u987b\u9009\u62e9\u4e00\u4e2a\u6b63\u786e\u7b54\u6848\u3002\u6b63\u786e\u7b54\u6848\u57df\u4e0d\u80fd\u4e3a\u7a7a\u3002
statistics_and_histo=\u7edf\u8ba1\u548c\u6761\u5f62\u56fe
strongly_agree=\u975e\u5e38\u540c\u610f
strongly_disagree=\u975e\u5e38\u4e0d\u540c\u610f
student_response=\u5b66\u751f\u56de\u7b54
student_rsquo_s_scor=\u5b66\u751f\u5f97\u5206
submission_message=\u63d0\u4ea4\u6d88\u606f
submissions=\u63d0\u4ea4
submissions_allowed=\u6b21\u63d0\u4ea4\u673a\u4f1a
submissions_allowed_error=\u65f6\u95f4\u5fc5\u987b\u662f\u6b63\u6574\u6570\uff0c\u598215\uff0c30\uff0c60
subnav_add_part=\u6dfb\u52a0\u5927\u9898
subnav_preview=\u9884\u89c8\u6d4b\u9a8c
subnav_print=\u6253\u5370\u9884\u89c8
subnav_publish=\u53d1\u5e03
subnav_settings=\u8bbe\u7f6e
subsub=subsub
sure_rem_q=\u786e\u8ba4\u5220\u9664\u8be5\u95ee\u9898\uff1f
t_addPart=\u6dfb\u52a0\u5927\u9898
t_assessment=\u6d4b\u9a8c
t_attachment=\u5728\u53e6\u4e00\u7a97\u53e3\u663e\u793a\u9644\u4ef6
t_editP=\u7f16\u8f91\u5927\u9898
t_editQ=\u7f16\u8f91\u95ee\u9898
t_preview=\u9884\u89c8\u6d4b\u9a8c
t_publish=\u53d1\u5e03
t_question=\u9898\u76ee
t_removeC=\u5220\u9664\u9009\u62e9
t_removeP=\u5220\u9664\u5927\u9898
t_removeQ=\u5220\u9664\u95ee\u9898
t_settings=\u7f16\u8f91\u8bbe\u7f6e
tf=\u6b63\u786e/\u9519\u8bef
the_complete_assessm=\u6574\u4e2a\u6d4b\u9a8c\u4e00\u4e2a\u9875\u9762\u3002
time_allowed_seconds=\u65f6\u95f4\u9650\u5236\uff08\u79d2\uff09
time_allowed_seconds_indic=\u6307\u793a\u7528\u6237\u56de\u7b54\u6240\u82b1\u65f6\u95f4
timed_assessment=\u8ba1\u65f6\u6d4b\u9a8c
timed_assessment_wit=\u8ba1\u65f6\u6d4b\u9a8c\u65f6\u9650
title=\u6807\u9898
title_navigoproject=\u6807\u9898\: NavigoProject.org
title_note=\u6ce8\uff1a\u6807\u9898\u4e3a\u201c\u9ed8\u8ba4\u201d\u7684\u90e8\u5206\u5bf9\u53d7\u6d4b\u8005\u4e0d\u53ef\u89c1\u3002
total_pt=\u603b\u5206
total_pts=\u603b\u5206
true_false=\u5224\u65ad\u9898
true_false_q=\u5224\u65ad\u9898
true_false_slash=\u6b63\u786e/\u9519\u8bef
true_msg=\u6b63\u786e
type=\u7c7b\u578b
type_of_randomization=\u968f\u673a\u7c7b\u578b
type_onebyone=\u4f9d\u6b21\u7f16\u5199\u95ee\u9898
unacceptable=\u4e0d\u53ef\u63a5\u53d7
undecided=\u4e0d\u786e\u5b9a
unlimited=\u4e0d\u9650
upload=\u4e0a\u4f20
upload_assessment=\u4e0a\u4f20\u6d4b\u9a8c
upload_instruction=\u70b9\u51fb\u201c\u6d4f\u89c8\u201d\u9009\u62e9\u4f60\u7684\u6587\u4ef6\uff0c\u7136\u540e\u70b9\u51fb\u201c\u4e0a\u4f20\u201d\u4e0a\u4f20\u6587\u4ef6\u3002
user_must_click_sav=\u7528\u6237\u987b\u70b9\u51fb\u201c\u4fdd\u5b58\u201d\u6309\u94ae\u4fdd\u5b58\u8f93\u5165\u3002
username=\u7528\u6237\u540d
warning=\u8b66\u544a\uff1a
what_is_regrade_republish_1=\u70b9\u51fb
what_is_regrade_republish_10=\u662f\u975e\u9898
what_is_regrade_republish_11=2\uff09\u4fee\u6539\u4e00\u4e2a\u81ea\u52a8\u8bc4\u5206\u95ee\u9898\u7684\u6b63\u786e\u7b54\u6848\u9009\u9879\u3002
what_is_regrade_republish_12=\u6ce8\u610f\uff1a\u5982\u679c\u4f60\u5728\u7f16\u8f91\u53d1\u5e03\u7684\u6d4b\u9a8c\u4e4b\u524d\u5df2\u5bf9\u81ea\u52a8\u8bc4\u5206\u7684\u95ee\u9898\u8fdb\u884c\u4e86\u624b\u52a8\u8c03\u6574\uff0c\u5355\u51fb\u91cd\u65b0\u8bc4\u5206\u5e76\u91cd\u65b0\u53d1\u5e03\u5c06\u8986\u76d6\u8fd9\u4e9b\u624b\u52a8\u8c03\u6574\u7684\u5206\u6570\u3002\u7136\u800c\uff0c\u624b\u52a8\u5206\u7ea7\u95ee\u9898\uff08\u4f8b\u5982\uff1a\u7b80\u7b54/\u8bba\u8ff0,\u5f55\u97f3\uff0c\u6587\u4ef6\u4e0a\u4f20\uff09\u5c06\u4e0d\u4f1a\u6539\u53d8\u3002
what_is_regrade_republish_2=\u91cd\u65b0\u8bc4\u5206\u5e76\u91cd\u65b0\u53d1\u5e03
what_is_regrade_republish_3=\u5982\u679c\u4f60\u5df2\u7ecf\u4fee\u6539\u4efb\u4f55\u4f1a\u5f71\u54cd\u5230\u6d4b\u9a8c\u7684\u7efc\u5408\u5206\u6570\u7684\u5730\u65b9\uff0c\u5305\u62ec\uff1a
what_is_regrade_republish_4=1\uff09\u5bf9\u4e8e\u4e00\u4e2a\u81ea\u52a8\u8bc4\u5206\u7684\u95ee\u9898\u4fee\u6539\u5176\u7b54\u6848\u5206\u503c\uff0c\u81ea\u52a8\u8bc4\u5206\u7684\u95ee\u9898\u7c7b\u578b\u5305\u62ec\uff1a
what_is_regrade_republish_5=\u591a\u9009\u9898
what_is_regrade_republish_6=\u8c03\u67e5
what_is_regrade_republish_7=\u586b\u7a7a\u9898
what_is_regrade_republish_8=\u6570\u5b57\u54cd\u5e94
what_is_regrade_republish_9=\u5339\u914d\u9898
what_is_republish_1=\u5355\u51fb
what_is_republish_2=\u91cd\u65b0\u53d1\u5e03
what_is_republish_3=\u5047\u8bbe\u4f60\u4fee\u6539\u7684\u5185\u5bb9\u4e0d\u5f71\u54cd\u6d4b\u9a8c\u7684\u7efc\u5408\u5206\u6570\uff08\u4f8b\u5982\uff1a\u4e00\u4e2a\u95ee\u9898\u6216\u5176\u7b54\u6848\u9009\u9879\u7684\u63aa\u8bcd\uff09
wildcard_char=\u63d2\u5165\u4e00\u4e2a\u661f\u53f7\u4ee3\u8868\u4e00\u4e2a\u6216\u591a\u4e2a\u901a\u914d\u7b26\u5b57\u6bcd
wildcard_example=\u4f8b\u5982\: It's raining {c*} and {d*s}.
yes=\u662f
yes_no=\u662f\uff0c\u5426
zero_survey=(0 \= \u8c03\u67e5\u6216\u4e3a\u8bc4\u5206\u95ee\u9898)
zeropoints=0\u5206
